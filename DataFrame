#create from columns:
file_columns=['id', 'month_start','month_end', 'day_start']
data_out=['ddaf',5,5,5]
data_output=pd.DataFrame([data_out], columns=file_columns)

# Create a dataFrame
import pandas as pd
A=pd.DataFrame({'Yes': [50,21], 'No':[131,2]}, index=['Prod A','Prod B'])

#Create Series
As=pd.Series([1,2,3],index=['2015 Sales', '2016 Sales', '2017 Sales'], name='Product A)
As.index #index

#get one cell
df.loc[1].at['age']
df.loc[1].age

#get last cell
df['time'].iloc[-1] # df.time[-1] does not work

#change one cell value
data.at[59,'HHP_maD']=0

#remove the outlier, which can be many cells 
data.at[data[data.HHP_maD>100].index, 'HHP_maD']=0

#Read file
w_reviews=pd.read_csv("...   ")
w_reviews.shape
w_reviews.head()

#Get items
w_reviews['country'][0]

#row first, column second for iloc and loc
w_reviews.iloc[0]
w_reviews.iloc[:,0]

w_reviews.loc[0:5,'country']

##BECAREFUL
Choosing between loc and iloc
When choosing or transitioning between loc and iloc, there is one "gotcha" worth keeping in mind, which is that the two methods use slightly different indexing schemes.

iloc uses the Python stdlib indexing scheme, where the first element of the range is included and the last one excluded. So 0:10 will select entries 0,...,9. 
loc, meanwhile, indexes inclusively. So 0:10 will select entries 0,...,10.

Why the change? Remember that loc can index any stdlib type: strings, for example. If we have a DataFrame with index values Apples, ..., Potatoes, ..., and we want to select "all the alphabetical fruit choices between Apples and Potatoes", then it's a lot more convenient to index df.loc['Apples':'Potatoes'] than it is to index something like df.loc['Apples', 'Potatoet] (t coming after s in the alphabet).

This is particularly confusing when the DataFrame index is a simple numerical list, e.g. 0,...,1000. In this case df.iloc[0:1000] will return 1000 entries, while df.loc[0:1000] return 1001 of them! To get 1000 elements using loc, you will need to go one lower and ask for df.loc[0:999].

Otherwise, the semantics of using loc are the same as those for iloc.

#set index
w_reviews.set_index("title")

##conditional selection:
w_reviews.country=='Italy'
w_reviews.loc[w_reviews.country == 'Italy']
reviews.loc[(reviews.country == 'Italy') & (reviews.points >= 90)]
reviews.loc[reviews.country.isin(['Italy', 'France'])]
reviews.loc[reviews.price.notnull()]

#Assigning data:
reviews['critic']='everyone'
reviews['index_backwards'] = range(len(reviews), 0, -1)

#summaries:
reviews.points.describe()
reviews.points.mean()
reviews.taster_name.unique()
reviews.taster_name.value_counts()

#Maps:
review_points_mean = reviews.points.mean()
reviews.points.map(lambda p: p - review_points_mean)
#apply
def remean_points(row):
    row.points = row.points - review_points_mean
    return row

reviews.apply(remean_points, axis='columns')

#Group
reviews.grouby('points').points.count() %same as to value_counts()
reviews.groupby('points').price.min()
reviews.groupby('winery').apply(lambda df: df.title.iloc[0])
reviews.groupby(['country', 'province']).apply(lambda df: df.loc[df.points.idxmax()])
reviews.groupby(['country']).price.agg([len, min, max]) # agg() generate simple statistics

#Multi-indexes
countries_reviewed = reviews.groupby(['country', 'province']).description.agg([len])
mi = countries_reviewed.index
countries_reviewed.reset_index()

#sort
countries_reviewed.sort_values(by='len', ascending=False)
countries_reviewed.sort_index()
countries_reviewed.sort_values(by=['country', 'len'])

#Dtype
reviews.price.dtype
reviews.dtypes
reviews.points.astype('float64')
reviews.index.dtype

#missing data
reviews[pd.isnull(reviews.country)]
reviews.region_2.fillna("Unknown")
reviews.taster_twitter_handle.replace("@kerinokeefe", "@kerino")

#rename
reviews.rename(columns={'points': 'score'})
reviews.rename(index={0: 'firstEntry', 1: 'secondEntry'})
reviews.rename_axis("wines", axis='rows').rename_axis("fields", axis='columns')

#combining
canadian_youtube = pd.read_csv("../input/youtube-new/CAvideos.csv")
british_youtube = pd.read_csv("../input/youtube-new/GBvideos.csv")
pd.concat([canadian_youtube, british_youtube])

#join
left = canadian_youtube.set_index(['title', 'trending_date'])
right = british_youtube.set_index(['title', 'trending_date'])

left.join(right, lsuffix='_CAN', rsuffix='_UK')

#unxtime to datetime
df['datetime']=pd.to_datetime(df['unxtime'], unix='s') #(unit ='s' for 10 digits unxtime)

#rolling
data.loc[:, column+'_ma']=data[column].fillna(0).rolling(ma_size, min_periods=1).mean() #where na to fill 0, min_periods prevent na in the beginning

#differential
data[column+'_diff']=data[column].diff(periods=1) #for 1 step differential signal
